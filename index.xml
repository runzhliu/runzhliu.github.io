<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>runzhliu</title>
    <link>https://runzhliu.github.io/</link>
    <description>Recent content on runzhliu</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Fri, 19 Jul 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://runzhliu.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Flink Session Cluster on K8S</title>
      <link>https://runzhliu.github.io/posts/flink-session-cluster-on-k8s/</link>
      <pubDate>Fri, 19 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://runzhliu.github.io/posts/flink-session-cluster-on-k8s/</guid>
      <description>1 Overview 本文是根据官方文档略加编辑整理出来的。
2 Setup Kubernetes Mac 环境推荐 Docker for Mac，一键部署。
实验过程中，应该注意你的 K8S 的版本等信息。
2 Flink session cluster on Kubernetes Flink session cluster 是作为 K8S 的 Deployment，Flink 的作业会被提交到 session cluster。至于什么是 Deployment，不清楚的同学可以看Deployment。Flink session cluster 会包含以下组件:
 JobManager 以 Deployment 的方式运行在 K8S 集群 TaskManagers 也是以 Deployment 的方式运行在 K8S 集群 JobManager 的 REST 和 UI 端口通过 Service 部署在 K8S 集群  2.1 Deploy Flink session cluster on Kubernetes 请按照官网的 Appendix将几个文件拷贝到本地。
然后就是部署，按照以下命令。
kubectl create -f jobmanager-service.</description>
    </item>
    
    <item>
      <title>Mac CPU 相关</title>
      <link>https://runzhliu.github.io/posts/mac-cpu-%E7%9B%B8%E5%85%B3/</link>
      <pubDate>Thu, 18 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://runzhliu.github.io/posts/mac-cpu-%E7%9B%B8%E5%85%B3/</guid>
      <description>1 Monitor  https://support.apple.com/zh-cn/HT201464
 这个是 Mac 自带的监视器，可以监视 包括 CPU，内存在内的多种资源，使用简单，可以针对某个进程进行 Kill。
2 命令模式 2.1 system_profiler SPHardwareDataType 2.2 sysctl sysctl 是可以提取内核状态的命令，具体用法可以 man sysctl 获取全面的手册，以下是从手册中获取的一些与 CPU 有关的指标。
   Name Type Changeable     hw.activecpu integer no   hw.cpu64bit_capable integer no   hw.cpufamily integer no   hw.cpufrequency integer no   hw.cpufrequency_max integer no   hw.cpufrequency_min integer no   hw.cpusubtype integer no   hw.</description>
    </item>
    
    <item>
      <title>Spark RDD依赖的深度优先搜索</title>
      <link>https://runzhliu.github.io/posts/spark-rdd%E4%BE%9D%E8%B5%96%E7%9A%84%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2/</link>
      <pubDate>Thu, 18 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://runzhliu.github.io/posts/spark-rdd%E4%BE%9D%E8%B5%96%E7%9A%84%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2/</guid>
      <description>1 Overview 最近在刷刷算法题，看到经典的树搜索的算法，正巧之前记得 Spark RDD 中有一处利用 DFS 来判断 RDD 依赖关系的代码，因此专门拿出来分析一下。
2 Code /** * Return the ancestors of the given RDD that are related to it only through a sequence of * narrow dependencies. This traverses the given RDD&amp;#39;s dependency tree using DFS, but maintains * no ordering on the RDDs returned. */ private[spark] def getNarrowAncestors: Seq[RDD[_]] = { val ancestors = new mutable.HashSet[RDD[_]] def visit(rdd: RDD[_]): Unit = { val narrowDependencies = rdd.</description>
    </item>
    
  </channel>
</rss>