<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>runzhliu</title>
    <link>https://runzhliu.github.io/</link>
    <description>Recent content on runzhliu</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Wed, 24 Jul 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://runzhliu.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Spark 面试题系列</title>
      <link>https://runzhliu.github.io/posts/spark-%E9%9D%A2%E8%AF%95%E9%A2%98%E7%B3%BB%E5%88%97/</link>
      <pubDate>Wed, 24 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://runzhliu.github.io/posts/spark-%E9%9D%A2%E8%AF%95%E9%A2%98%E7%B3%BB%E5%88%97/</guid>
      <description>之前在知乎上整理过一些 Spark 常问的面试题，知识有点老旧了，而且当时没有太注重排版，计划从这篇开始，逐渐将原来的面试题文档给取代掉，预计每篇大概整理10条问题，对 Spark 一些基础知识点，尤其是面试的时候会碰到的问题，来一个总结。
总结的顺序可能是无序的，也就是说，不一定是由浅入深，但是应该是比较「口水化」的问答模式。</description>
    </item>
    
    <item>
      <title>大规模离线计算产品的调研</title>
      <link>https://runzhliu.github.io/posts/%E5%A4%A7%E8%A7%84%E6%A8%A1%E7%A6%BB%E7%BA%BF%E8%AE%A1%E7%AE%97%E4%BA%A7%E5%93%81%E7%9A%84%E8%B0%83%E7%A0%94/</link>
      <pubDate>Mon, 22 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://runzhliu.github.io/posts/%E5%A4%A7%E8%A7%84%E6%A8%A1%E7%A6%BB%E7%BA%BF%E8%AE%A1%E7%AE%97%E4%BA%A7%E5%93%81%E7%9A%84%E8%B0%83%E7%A0%94/</guid>
      <description>Background 资源调度  国内市面上的专用的大数据离线计算产品，一般都是采用 Hadoop 集群托管的方式，此类型的产品，大部分都是基于 YARN 来资源调度的。 国外已经有云厂商（AWS, Azure, GCP）提供基于 Kubernetes 的容器化计算产品。  产品形态  Level0: Kubernetes 集群 Level1: 定制化的平台，日志收集/分析，用户画像，推荐等产品  1 传统计算集群 1.1 腾讯云-弹性 MapReduce  https://cloud.tencent.com/document/product/589
 弹性 MapReduce（EMR）结合云技术和 Hadoop、Hive、Spark、Storm 等社区开源技术，提供安全、低成本、高可靠、可弹性伸缩的云端托管 Hadoop 服务。您可以在数分钟内创建安全可靠的专属 Hadoop 集群，以分析位于集群内数据节点或 COS 上的 PB 级海量数据。
 runzhliu: 关于 Spark 或者类似的离线/流计算，面向的是 Spark 开发者，自由度非常高，但是不适合分析师等用户，具体可以看相关的文档Spark 分析 COS 上的数据。
 1.2 腾讯云-云数据仓库套件 Sparkling  https://cloud.tencent.com/product/sparkling
 云数据仓库套件 Sparkling（Tencent Sparkling Data Warehouse Suite）为您提供一套全托管、简单易用的、高性能的PB级云端数据仓库解决方案。Sparkling 基于业界领先的 Apache Spark 框架，您可以在数分钟内创建数千节点的企业级云端分布式数据仓库，并高效的按需快速弹性扩缩容。通过一站式大数据开发和科学平台 DataStudio 进行集群管控、数据集成、元数据管理、工作流开发、数据加工处理、结果可视化等操作，深度集成商业智能分析 BI，构建应用数据集市，提供海量数据的离线加工、数据建模、即席查询分析、数据挖掘和可视化探查能力。</description>
    </item>
    
    <item>
      <title>Docker ENTRYPOINT 笔记</title>
      <link>https://runzhliu.github.io/posts/docker-entrypoint-%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Sun, 21 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://runzhliu.github.io/posts/docker-entrypoint-%E7%AC%94%E8%AE%B0/</guid>
      <description>1 Overview Docker 中 ENTRYPOINT 一直是个容易混淆的概念，今天浏览了一下官网，简单总结一下。官网的参考链接如下。
 https://docs.docker.com/search/?q=entrypoint
 2 ENTRYPOINT 在 Dockerfile 中，ENTRYPOINT 是作为容器运行的命令存在的，但是他是非必须的，原因是除了可以在 Dockerfile 中填写 ENTRYPOINT，你还可以写 CMD，甚至同时使用两者。
如果指定了 ENTRYPOINT，大部分的 Docker 镜像都定义了 ENTRYPOINT，即使不写，你依然可以从你的 base 镜像中获取到 ENTRYPOINT，前提当然是 base 镜像有定义。另外，就算你的 Dockerfile 定义了 ENTRYPOINT，你还可以通过命令行的模式，在启动容器的时候提供 --entrypoint 选项来覆盖。下面的例子的含义是，通过 --entrypoint 来覆盖 Dockerfile 里定义的 ENTRYPOINT，然后给 CMD 命令传入 -l /tmp 的命令。
$ docker run --entrypoint=/bin/ls ubuntu -l /tmp ---结果--- total 0 以上例子，你可以想象成你定义的 Dockerfile 是这样的。
FROM ubuntu ENTRYPOINT [&amp;#34;/bin/ls&amp;#34;] CMD [&amp;#34;-l&amp;#34;, &amp;#34;/tmp&amp;#34;] 3 Summary 实践中，ENTRYPOINT 并不会经常被覆盖，但是如果镜像文件中指定了 ENTRYPOINT，那么一定程度上，会让你的镜像更 flexible，或者说更容易使用。</description>
    </item>
    
    <item>
      <title>RUN, CMD, ENTRYPOINT in Docker</title>
      <link>https://runzhliu.github.io/posts/run-cmd-entrypoint-in-docker/</link>
      <pubDate>Sun, 21 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://runzhliu.github.io/posts/run-cmd-entrypoint-in-docker/</guid>
      <description>1 Overview 网上的 Dockerfile 很好找，同时也很好 copy，但是当真正需要自己去写 Dockerfile 的时候还是会有不少让人感觉 confused 的地方，就比如 RUN, CMD 和 ENTRYPOINT 这三个指令看上去很类似，很容易混淆，写的时候有些时候能够通用，但是却又得到不同的效果。
2 Shell 和 Exec 格式 我们可用两种方式指定 RUN、CMD 和 ENTRYPOINT 要运行的命令：Shell 格式和 Exec 格式，二者在使用上有细微的区别。
2.1 Shell 格式 Shell 格式 &amp;lt;instruction&amp;gt; &amp;lt;command&amp;gt; 例如：
# Shell 格式的 Run RUN apt-get install python3 # Shell 格式的 CMD CMD echo &amp;#34;Hello world&amp;#34; # Shell 格式的 ENTRYPOINT ENTRYPOINT echo &amp;#34;Hello world&amp;#34;  当指令执行时，Shell 格式底层会调用 /bin/sh -c &amp;lt;command&amp;gt;。
所以上述命令，其实底层是执行了这样的命令。
# Shell 格式的 Run RUN /bin/sh -c apt-get install python3 # Shell 格式的 CMD CMD /bin/sh -c echo &amp;#34;Hello world&amp;#34; # Shell 格式的 ENTRYPOINT ENTRYPOINT /bin/sh -c echo &amp;#34;Hello world&amp;#34;  例如下面的 Dockerfile 片段，指定了 ENV：</description>
    </item>
    
    <item>
      <title>如何判断环境变量为空</title>
      <link>https://runzhliu.github.io/posts/%E5%A6%82%E4%BD%95%E5%88%A4%E6%96%AD%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E4%B8%BA%E7%A9%BA/</link>
      <pubDate>Sun, 21 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://runzhliu.github.io/posts/%E5%A6%82%E4%BD%95%E5%88%A4%E6%96%AD%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E4%B8%BA%E7%A9%BA/</guid>
      <description>1 Overview 今天在看 Spark 的脚本的时候，发现很多变量都有用到 {VARIABLE+x} 这种格式，如下：
... ... ... &amp;amp;&amp;amp; if ! [ -z ${SPARK_MOUNTED_CLASSPATH+x} ]; then SPARK_CLASSPATH=&amp;#34;$SPARK_MOUNTED_CLASSPATH:$SPARK_CLASSPATH&amp;#34;; fi \ ... ... ... -z 很容易理解，在 Shell 脚本里就是表示后面这个变量是否为空，也做 zero 的意思。那后面的 +x 呢？
2 Example 以下例子是先定义了 VARIABLE 变量为空，然后判断为空的时候输出需要设置环境变量，不为空则打印变量值。
VARIABLE= if ! [ -z ${VARIABLE} ]; then echo &amp;#34;${VARIABLE}was defined&amp;#34; else echo &amp;#34;Need to set environment var $VARIABLE&amp;#34; &amp;amp;&amp;amp; exit 1; fi 显示结果如下。结果判断是正确的。
➜ /tmp cat x.sh VARIABLE= if ! [ -z ${VARIABLE} ]; then echo &amp;#34;${VARIABLE} was defined&amp;#34; else echo &amp;#34;Need to set environment var $VARIABLE&amp;#34; &amp;amp;&amp;amp; exit 1; fi ➜ /tmp .</description>
    </item>
    
    <item>
      <title>Flink Dockerfile 走读</title>
      <link>https://runzhliu.github.io/posts/flink-dockerfile-%E8%B5%B0%E8%AF%BB/</link>
      <pubDate>Sat, 20 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://runzhliu.github.io/posts/flink-dockerfile-%E8%B5%B0%E8%AF%BB/</guid>
      <description>1 Overview 关于 Flink 的 Docker 相关的配置，可以参考源码这个目录。
/path/to/flink/flink-container/docker ├── Dockerfile // Dockerfile ├── README.md // 具体的说明，如何创建 Flink 的镜像文件 ├── build.sh // ├── docker-compose.yml // └── docker-entrypoint.sh // Dockerfile 中运行的脚本 2 Dockerfile # 省略了 License，特此声明 FROM openjdk:8-jre-alpine # 安装需要的软件 # snappy 是一个压缩库 # libc6-compat 是 ANSI C 的函数库 RUN apk add --no-cache bash snappy libc6-compat # Flink 容器里的环境变量 # Flink 软件的安装目录在 /opt ENV FLINK_INSTALL_PATH=/opt # Flikn 的解压目录在 /opt/flink ENV FLINK_HOME $FLINK_INSTALL_PATH/flink # Flink 的依赖包目录在 /opt/flink/lib ENV FLINK_LIB_DIR $FLINK_HOME/lib # Flink 的插件目录在 /opt/flink/plugins ENV FLINK_PLUGINS_DIR $FLINK_HOME/plugins # 这个不知道是什么目录 ENV FLINK_OPT_DIR $FLINK_HOME/opt # 这是用户代码的 Jar 包目录，/opt/flink/artifacts ENV FLINK_JOB_ARTIFACTS_DIR $FLINK_INSTALL_PATH/artifacts # 更新一下 PATH，把 Flink 的二进制文件的目录加上 /opt/flink/bin ENV PATH $PATH:$FLINK_HOME/bin # 这些 ARG 可以在构建镜像的时候输入参数，默认值都是 NOT_SET，如果设置了就会去找对应的目录，并且打入镜像里 # Flink 的发行版路径，可以在本地指定任何下载或者自行打包的 Flink 发行版包 ARG flink_dist=NOT_SET # 用户写的业务代码路径 ARG job_artifacts=NOT_SET # Python 的版本，填2或者3 ARG python_version=NOT_SET # Hadoop Jar 包的依赖路径 ARG hadoop_jar=NOT_SET* # 安装 Python，根据前面填的 python_version 这个环境变量，不填就不装 RUN \ if [ &amp;#34;$python_version&amp;#34; = &amp;#34;2&amp;#34; ]; then \ apk add --no-cache python; \ elif [ &amp;#34;$python_version&amp;#34; = &amp;#34;3&amp;#34; ]; then \ apk add --no-cache python3 &amp;amp;&amp;amp; ln -s /usr/bin/python3 /usr/bin/python; \ fi # 把 Flink 发行版和 Hadoop jar（不一定有 Hadoop）放在 /opt/flink 目录 ADD $flink_dist $hadoop_jar $FLINK_INSTALL_PATH/ # 用户代码放在 /opt/artifacts ADD $job_artifacts/* $FLINK_JOB_ARTIFACTS_DIR/ RUN set -x &amp;amp;&amp;amp; \ ln -s $FLINK_INSTALL_PATH/flink-[0-9]* $FLINK_HOME &amp;amp;&amp;amp; \ for jar in $FLINK_JOB_ARTIFACTS_DIR/*.</description>
    </item>
    
    <item>
      <title>Flink Job Cluster on Kubernetes</title>
      <link>https://runzhliu.github.io/posts/flink-job-cluster-on-kubernetes/</link>
      <pubDate>Sat, 20 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://runzhliu.github.io/posts/flink-job-cluster-on-kubernetes/</guid>
      <description>1 Overview 之前文章介绍了 Flink session cluster on Kubernetes，需要注意，这种部署方式，可以在同一个 Cluster 上多次提交 Flink Job，而本文介绍的，是一种将任务和镜像绑定的部署方式，即 Flink 集群是不共享的，其组件是单独属于一个 Job。
2 Creating the job-specific image 可以参考之前另一篇文章。上一篇文章打出来的镜像是一个用了官方提供的 WordCount 例子，在部署 Flink job cluster 的重点在于把用户要运行的 Job 代码放入镜像，此处不赘述了。
3 Deploy Flink job cluster on Kubernetes 官方提供了 Service 和 Job 的模板用于在 K8S 集群上运行 Flink 任务。这里需要注意，模板里面有两个变量，需要用户自行填写。
 ${FLINK_IMAGE_NAME}: Flink 镜像文件的名字 ${FLINK_JOB_PARALLELISM}: Flink Job 的并行度，可以理解成需要的 TaskManager 的个数（Pod 数量）  然后官网也提供了一个命令。
FLINK_IMAGE_NAME=&amp;lt;IMAGE_NAME&amp;gt; FLINK_JOB_PARALLELISM=&amp;lt;PARALLELISM&amp;gt; envsubst &amp;lt; job-cluster-job.yaml.template | kubectl create -f - 当然，直接运行会报错的，除了填充变量以外，envsubst 也是个坑爹的工具，他其实就是用来替换文件中的占位变量的工具，Mac 用户可以通过 brew install gettext，安装完部分用户会发现 envsubst 命令还是用不了，如果不行的用户可以尝试运行下面的命令，直接去找到 envsusbt 运行文件的路径。配置好之后，这个命令就可以运行了。</description>
    </item>
    
    <item>
      <title>Flink 集群-任务容器化</title>
      <link>https://runzhliu.github.io/posts/flink-%E9%9B%86%E7%BE%A4-%E4%BB%BB%E5%8A%A1%E5%AE%B9%E5%99%A8%E5%8C%96/</link>
      <pubDate>Sat, 20 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://runzhliu.github.io/posts/flink-%E9%9B%86%E7%BE%A4-%E4%BB%BB%E5%8A%A1%E5%AE%B9%E5%99%A8%E5%8C%96/</guid>
      <description>1 Overview /path/to/flink/flink-container/docker ├── Dockerfile ├── README.md ├── build.sh ├── docker-compose.yml ├── docker-entrypoint.sh └── test-job-cluster.sh 0 directories, 6 files Flink Dockerfile 走读已经介绍了 Flink 的镜像应该如何构建了，接下来，本文解释一下如何利用 Docker 来部署 Flink。
2 Docker Compose 以下是 docker-compose.yml 的内容。
# 省略 License # Docker compose file for a Flink job cluster deployment. # 注意下面这些参数的设置 # Parameters: # * FLINK_DOCKER_IMAGE_NAME - Image name to use for the deployment (default: flink-job:latest) # * FLINK_JOB - Name of the Flink job to execute (default: none) # * DEFAULT_PARALLELISM - Default parallelism with which to start the job (default: 1) # * FLINK_JOB_ARGUMENTS - Additional arguments which will be passed to the job cluster (default: none) # * SAVEPOINT_OPTIONS - Savepoint options to start the cluster with (default: none) version: &amp;#34;2.</description>
    </item>
    
    <item>
      <title>Flink Session Cluster on K8S</title>
      <link>https://runzhliu.github.io/posts/flink-session-cluster-on-k8s/</link>
      <pubDate>Fri, 19 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://runzhliu.github.io/posts/flink-session-cluster-on-k8s/</guid>
      <description>1 Overview 本文是根据官方文档略加编辑整理出来的。
2 Setup Kubernetes Mac 环境推荐 Docker for Mac，一键部署。
实验过程中，应该注意你的 K8S 的版本等信息。
2 Flink session cluster on Kubernetes Flink session cluster 是作为 K8S 的 Deployment，Flink 的作业会被提交到 session cluster。至于什么是 Deployment，不清楚的同学可以看Deployment。Flink session cluster 会包含以下组件:
 JobManager 以 Deployment 的方式运行在 K8S 集群 TaskManagers 也是以 Deployment 的方式运行在 K8S 集群 JobManager 的 REST 和 UI 端口通过 Service 部署在 K8S 集群  2.1 Deploy Flink session cluster on Kubernetes 请按照官网的 Appendix将几个文件拷贝到本地。
然后就是部署，按照以下命令。
kubectl create -f jobmanager-service.</description>
    </item>
    
    <item>
      <title>Mac CPU 相关</title>
      <link>https://runzhliu.github.io/posts/mac-cpu-%E7%9B%B8%E5%85%B3/</link>
      <pubDate>Thu, 18 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://runzhliu.github.io/posts/mac-cpu-%E7%9B%B8%E5%85%B3/</guid>
      <description>1 Monitor  https://support.apple.com/zh-cn/HT201464
 这个是 Mac 自带的监视器，可以监视 包括 CPU，内存在内的多种资源，使用简单，可以针对某个进程进行 Kill。
2 命令模式 2.1 system_profiler SPHardwareDataType 2.2 sysctl sysctl 是可以提取内核状态的命令，具体用法可以 man sysctl 获取全面的手册，以下是从手册中获取的一些与 CPU 有关的指标。
   Name Type Changeable     hw.activecpu integer no   hw.cpu64bit_capable integer no   hw.cpufamily integer no   hw.cpufrequency integer no   hw.cpufrequency_max integer no   hw.cpufrequency_min integer no   hw.cpusubtype integer no   hw.</description>
    </item>
    
    <item>
      <title>Spark RDD 依赖的深度优先搜索</title>
      <link>https://runzhliu.github.io/posts/spark-rdd%E4%BE%9D%E8%B5%96%E7%9A%84%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2/</link>
      <pubDate>Thu, 18 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://runzhliu.github.io/posts/spark-rdd%E4%BE%9D%E8%B5%96%E7%9A%84%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2/</guid>
      <description>1 Overview 最近在刷刷算法题，看到经典的树搜索的算法，正巧之前记得 Spark RDD 中有一处利用 DFS 来判断 RDD 依赖关系的代码，因此专门拿出来分析一下。
2 Code /** * Return the ancestors of the given RDD that are related to it only through a sequence of * narrow dependencies. This traverses the given RDD&amp;#39;s dependency tree using DFS, but maintains * no ordering on the RDDs returned. */ private[spark] def getNarrowAncestors: Seq[RDD[_]] = { val ancestors = new mutable.HashSet[RDD[_]] def visit(rdd: RDD[_]): Unit = { val narrowDependencies = rdd.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://runzhliu.github.io/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://runzhliu.github.io/about/</guid>
      <description>本人毕业于中山大学，曾就职于 eBay, 丁香园，OPPO 等公司，目前就职于腾讯，工作内容主要是以 Kubernetes 作为基础设施，构建大规模离线计算平台。
 对个性化推荐系统架构有深入了解，具有实际开发和高并发、高可用系统架构设计的相关经验，熟悉常见的推荐算法和常用的统计/机器学习算法。具有推荐相关系统，如配置管理、实时处理，AB 测试实验平台等研发和优化经验。 有实时和离线大数据处理经验，有实际用户画像的构建和应用的经验，熟悉大数据数据仓库分层架构，参与过海量分布式数据平台系统的建设和落地。 掌握使用各种大数据分布式计算框架，实时流处理计算框架，拥有基于 Hadoop, Spark, CarbonData, HBase, Hive, Elasticsearch, Redis 等分布式计算框架的算法设计经验，对大数据生态技术体系有较多了解。 实际项目中有重度使用过 Elasticsearch, Redis, HBase, Kafka, Spark, Akka 等等。有使用 Docker 部署应用的经验。阅读过 Spark 部分模块的源码。  </description>
    </item>
    
  </channel>
</rss>